{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "998dbc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5189e673",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/nicknochnack/Tensorflow-in-10-Minutes/main/Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6a85eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(df.drop(['Churn', 'Customer ID'], axis=1))\n",
    "y = df['Churn'].apply(lambda x: 1 if x=='Yes' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12149947",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f39628f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "877     1\n",
       "733     0\n",
       "6000    0\n",
       "5467    0\n",
       "3570    0\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "495ca639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc15faeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9b1e1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building and compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dcc1aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=32, activation='relu', input_dim=len(X_train.columns)))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d935562e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf51f195",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b528cddc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type int).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:103\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    101\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    102\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type int)."
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=200, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83caac68",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39masarray(X_train)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m      2\u001b[0m y_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(y_train)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "X_train = np.asarray(X_train).astype(np.float32)\n",
    "y_train = np.asarray(y_train).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8a0591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9941ae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train).astype(np.float32)\n",
    "y_train = np.asarray(y_train).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4529a0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "177/177 [==============================] - 3s 4ms/step - loss: 0.5053 - accuracy: 0.7560\n",
      "Epoch 2/200\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 0.4860 - accuracy: 0.7721\n",
      "Epoch 3/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4805 - accuracy: 0.7778\n",
      "Epoch 4/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4780 - accuracy: 0.7783\n",
      "Epoch 5/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4720 - accuracy: 0.7808\n",
      "Epoch 6/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4705 - accuracy: 0.7817\n",
      "Epoch 7/200\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 0.4743 - accuracy: 0.7840\n",
      "Epoch 8/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4654 - accuracy: 0.7858\n",
      "Epoch 9/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4655 - accuracy: 0.7823\n",
      "Epoch 10/200\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 0.4624 - accuracy: 0.7886\n",
      "Epoch 11/200\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 0.4617 - accuracy: 0.7833\n",
      "Epoch 12/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4610 - accuracy: 0.7847\n",
      "Epoch 13/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4592 - accuracy: 0.7847\n",
      "Epoch 14/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4567 - accuracy: 0.7858\n",
      "Epoch 15/200\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 0.4572 - accuracy: 0.7847\n",
      "Epoch 16/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4554 - accuracy: 0.7872\n",
      "Epoch 17/200\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 0.4535 - accuracy: 0.7840\n",
      "Epoch 18/200\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 0.4525 - accuracy: 0.7895\n",
      "Epoch 19/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4537 - accuracy: 0.7881\n",
      "Epoch 20/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4532 - accuracy: 0.7867\n",
      "Epoch 21/200\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 0.4528 - accuracy: 0.7874\n",
      "Epoch 22/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4535 - accuracy: 0.7909\n",
      "Epoch 23/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4503 - accuracy: 0.7853\n",
      "Epoch 24/200\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 0.4487 - accuracy: 0.7885\n",
      "Epoch 25/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4515 - accuracy: 0.7839\n",
      "Epoch 26/200\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 0.4512 - accuracy: 0.7890\n",
      "Epoch 27/200\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 0.4512 - accuracy: 0.7886\n",
      "Epoch 28/200\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 0.4479 - accuracy: 0.7890\n",
      "Epoch 29/200\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 0.4498 - accuracy: 0.7869\n",
      "Epoch 30/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4482 - accuracy: 0.7862\n",
      "Epoch 31/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4479 - accuracy: 0.7895\n",
      "Epoch 32/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4480 - accuracy: 0.7862\n",
      "Epoch 33/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4480 - accuracy: 0.7885\n",
      "Epoch 34/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4463 - accuracy: 0.7915\n",
      "Epoch 35/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4463 - accuracy: 0.7883\n",
      "Epoch 36/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4467 - accuracy: 0.7837\n",
      "Epoch 37/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4471 - accuracy: 0.7913\n",
      "Epoch 38/200\n",
      "177/177 [==============================] - 1s 3ms/step - loss: 0.4472 - accuracy: 0.7849\n",
      "Epoch 39/200\n",
      "177/177 [==============================] - 1s 3ms/step - loss: 0.4443 - accuracy: 0.7858\n",
      "Epoch 40/200\n",
      "177/177 [==============================] - 1s 3ms/step - loss: 0.4456 - accuracy: 0.7899\n",
      "Epoch 41/200\n",
      "177/177 [==============================] - 1s 3ms/step - loss: 0.4455 - accuracy: 0.7881\n",
      "Epoch 42/200\n",
      "177/177 [==============================] - 1s 3ms/step - loss: 0.4466 - accuracy: 0.7876\n",
      "Epoch 43/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4432 - accuracy: 0.7911\n",
      "Epoch 44/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4433 - accuracy: 0.7899\n",
      "Epoch 45/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4474 - accuracy: 0.7883\n",
      "Epoch 46/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4437 - accuracy: 0.7895\n",
      "Epoch 47/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4437 - accuracy: 0.7886\n",
      "Epoch 48/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4427 - accuracy: 0.7860\n",
      "Epoch 49/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4433 - accuracy: 0.7883\n",
      "Epoch 50/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4412 - accuracy: 0.7899\n",
      "Epoch 51/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4445 - accuracy: 0.7890\n",
      "Epoch 52/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4416 - accuracy: 0.7892\n",
      "Epoch 53/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4425 - accuracy: 0.7915\n",
      "Epoch 54/200\n",
      "177/177 [==============================] - 1s 3ms/step - loss: 0.4411 - accuracy: 0.7892\n",
      "Epoch 55/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4411 - accuracy: 0.7890\n",
      "Epoch 56/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4413 - accuracy: 0.7886\n",
      "Epoch 57/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4403 - accuracy: 0.7870\n",
      "Epoch 58/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4415 - accuracy: 0.7901\n",
      "Epoch 59/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4398 - accuracy: 0.7909\n",
      "Epoch 60/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4403 - accuracy: 0.7901\n",
      "Epoch 61/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4400 - accuracy: 0.7927\n",
      "Epoch 62/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4422 - accuracy: 0.7881\n",
      "Epoch 63/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4414 - accuracy: 0.7858\n",
      "Epoch 64/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4392 - accuracy: 0.7876\n",
      "Epoch 65/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4383 - accuracy: 0.7870\n",
      "Epoch 66/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4385 - accuracy: 0.7915\n",
      "Epoch 67/200\n",
      "177/177 [==============================] - 1s 3ms/step - loss: 0.4406 - accuracy: 0.7906\n",
      "Epoch 68/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4392 - accuracy: 0.7906\n",
      "Epoch 69/200\n",
      "177/177 [==============================] - 1s 3ms/step - loss: 0.4349 - accuracy: 0.7897\n",
      "Epoch 70/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4366 - accuracy: 0.7917\n",
      "Epoch 71/200\n",
      "177/177 [==============================] - 1s 3ms/step - loss: 0.4368 - accuracy: 0.7929\n",
      "Epoch 72/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4405 - accuracy: 0.7924\n",
      "Epoch 73/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4359 - accuracy: 0.7885\n",
      "Epoch 74/200\n",
      "177/177 [==============================] - 1s 3ms/step - loss: 0.4373 - accuracy: 0.7925\n",
      "Epoch 75/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4386 - accuracy: 0.7883\n",
      "Epoch 76/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4369 - accuracy: 0.7963\n",
      "Epoch 77/200\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 0.4354 - accuracy: 0.7941\n",
      "Epoch 78/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4364 - accuracy: 0.7902\n",
      "Epoch 79/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4373 - accuracy: 0.7899\n",
      "Epoch 80/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4359 - accuracy: 0.7936\n",
      "Epoch 81/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4384 - accuracy: 0.7943\n",
      "Epoch 82/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4378 - accuracy: 0.7899\n",
      "Epoch 83/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4373 - accuracy: 0.7920\n",
      "Epoch 84/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4350 - accuracy: 0.7922\n",
      "Epoch 85/200\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 0.4333 - accuracy: 0.7965\n",
      "Epoch 86/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4360 - accuracy: 0.7876\n",
      "Epoch 87/200\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 0.4344 - accuracy: 0.7913\n",
      "Epoch 88/200\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 0.4309 - accuracy: 0.7934\n",
      "Epoch 89/200\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 0.4314 - accuracy: 0.7965\n",
      "Epoch 90/200\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 0.4323 - accuracy: 0.7963\n",
      "Epoch 91/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4317 - accuracy: 0.7950\n",
      "Epoch 92/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4381 - accuracy: 0.7890\n",
      "Epoch 93/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4357 - accuracy: 0.7925\n",
      "Epoch 94/200\n",
      "177/177 [==============================] - 1s 3ms/step - loss: 0.4327 - accuracy: 0.7950\n",
      "Epoch 95/200\n",
      "177/177 [==============================] - 1s 3ms/step - loss: 0.4335 - accuracy: 0.7920\n",
      "Epoch 96/200\n",
      "177/177 [==============================] - 1s 3ms/step - loss: 0.4342 - accuracy: 0.7927\n",
      "Epoch 97/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4332 - accuracy: 0.7895\n",
      "Epoch 98/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4310 - accuracy: 0.7925\n",
      "Epoch 99/200\n",
      "177/177 [==============================] - 1s 3ms/step - loss: 0.4317 - accuracy: 0.7947\n",
      "Epoch 100/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4335 - accuracy: 0.7929\n",
      "Epoch 101/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4312 - accuracy: 0.7936\n",
      "Epoch 102/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4308 - accuracy: 0.7936\n",
      "Epoch 103/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4330 - accuracy: 0.7965\n",
      "Epoch 104/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4324 - accuracy: 0.7943\n",
      "Epoch 105/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4299 - accuracy: 0.7940\n",
      "Epoch 106/200\n",
      "177/177 [==============================] - 1s 3ms/step - loss: 0.4304 - accuracy: 0.7938\n",
      "Epoch 107/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4312 - accuracy: 0.7941\n",
      "Epoch 108/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4329 - accuracy: 0.7959\n",
      "Epoch 109/200\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 0.4307 - accuracy: 0.7963\n",
      "Epoch 110/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4297 - accuracy: 0.7936\n",
      "Epoch 111/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4329 - accuracy: 0.7947\n",
      "Epoch 112/200\n",
      "177/177 [==============================] - 1s 3ms/step - loss: 0.4290 - accuracy: 0.7945\n",
      "Epoch 113/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4315 - accuracy: 0.7934\n",
      "Epoch 114/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4288 - accuracy: 0.7945\n",
      "Epoch 115/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4393 - accuracy: 0.7897\n",
      "Epoch 116/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4331 - accuracy: 0.7918\n",
      "Epoch 117/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4323 - accuracy: 0.7933\n",
      "Epoch 118/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4281 - accuracy: 0.7961\n",
      "Epoch 119/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4301 - accuracy: 0.7924\n",
      "Epoch 120/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4286 - accuracy: 0.7966\n",
      "Epoch 121/200\n",
      "177/177 [==============================] - 1s 3ms/step - loss: 0.4327 - accuracy: 0.7970\n",
      "Epoch 122/200\n",
      "177/177 [==============================] - 1s 3ms/step - loss: 0.4297 - accuracy: 0.7996\n",
      "Epoch 123/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4260 - accuracy: 0.7966\n",
      "Epoch 124/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4300 - accuracy: 0.7902\n",
      "Epoch 125/200\n",
      "177/177 [==============================] - 1s 3ms/step - loss: 0.4376 - accuracy: 0.7933\n",
      "Epoch 126/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4301 - accuracy: 0.7925\n",
      "Epoch 127/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4279 - accuracy: 0.7938\n",
      "Epoch 128/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4285 - accuracy: 0.7961\n",
      "Epoch 129/200\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 0.4292 - accuracy: 0.7938\n",
      "Epoch 130/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4301 - accuracy: 0.7952\n",
      "Epoch 131/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4271 - accuracy: 0.7980\n",
      "Epoch 132/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4282 - accuracy: 0.7938\n",
      "Epoch 133/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4298 - accuracy: 0.7922\n",
      "Epoch 134/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4287 - accuracy: 0.7957\n",
      "Epoch 135/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4318 - accuracy: 0.7940\n",
      "Epoch 136/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4307 - accuracy: 0.7970\n",
      "Epoch 137/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4295 - accuracy: 0.7917\n",
      "Epoch 138/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4309 - accuracy: 0.7938\n",
      "Epoch 139/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4257 - accuracy: 0.7998\n",
      "Epoch 140/200\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 0.4272 - accuracy: 0.7986\n",
      "Epoch 141/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4263 - accuracy: 0.7959\n",
      "Epoch 142/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4270 - accuracy: 0.7968\n",
      "Epoch 143/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4271 - accuracy: 0.7938\n",
      "Epoch 144/200\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 0.4260 - accuracy: 0.7957\n",
      "Epoch 145/200\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 0.4230 - accuracy: 0.7977\n",
      "Epoch 146/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4264 - accuracy: 0.7945\n",
      "Epoch 147/200\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 0.4269 - accuracy: 0.7947\n",
      "Epoch 148/200\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 0.4249 - accuracy: 0.7970\n",
      "Epoch 149/200\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 0.4275 - accuracy: 0.7897\n",
      "Epoch 150/200\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 0.4278 - accuracy: 0.7956\n",
      "Epoch 151/200\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 0.4269 - accuracy: 0.7963\n",
      "Epoch 152/200\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 0.4254 - accuracy: 0.7989\n",
      "Epoch 153/200\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 0.4259 - accuracy: 0.7945\n",
      "Epoch 154/200\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 0.4263 - accuracy: 0.7957\n",
      "Epoch 155/200\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 0.4260 - accuracy: 0.7959\n",
      "Epoch 156/200\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 0.4243 - accuracy: 0.7957\n",
      "Epoch 157/200\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 0.4250 - accuracy: 0.7998\n",
      "Epoch 158/200\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 0.4269 - accuracy: 0.7931\n",
      "Epoch 159/200\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 0.4258 - accuracy: 0.7991\n",
      "Epoch 160/200\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 0.4256 - accuracy: 0.7991\n",
      "Epoch 161/200\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 0.4249 - accuracy: 0.7954\n",
      "Epoch 162/200\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 0.4210 - accuracy: 0.8000\n",
      "Epoch 163/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4239 - accuracy: 0.7957\n",
      "Epoch 164/200\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 0.4315 - accuracy: 0.7911\n",
      "Epoch 165/200\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 0.4248 - accuracy: 0.7966\n",
      "Epoch 166/200\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 0.4258 - accuracy: 0.7966\n",
      "Epoch 167/200\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 0.4259 - accuracy: 0.8046\n",
      "Epoch 168/200\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 0.4237 - accuracy: 0.7963\n",
      "Epoch 169/200\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 0.4237 - accuracy: 0.7949\n",
      "Epoch 170/200\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 0.4278 - accuracy: 0.7927\n",
      "Epoch 171/200\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 0.4230 - accuracy: 0.7991\n",
      "Epoch 172/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4250 - accuracy: 0.7950\n",
      "Epoch 173/200\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 0.4260 - accuracy: 0.7996\n",
      "Epoch 174/200\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 0.4250 - accuracy: 0.7956\n",
      "Epoch 175/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4198 - accuracy: 0.8035\n",
      "Epoch 176/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4245 - accuracy: 0.7952\n",
      "Epoch 177/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4239 - accuracy: 0.7936\n",
      "Epoch 178/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4234 - accuracy: 0.7945\n",
      "Epoch 179/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4231 - accuracy: 0.8012\n",
      "Epoch 180/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4217 - accuracy: 0.7941\n",
      "Epoch 181/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4263 - accuracy: 0.7972\n",
      "Epoch 182/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4245 - accuracy: 0.7991\n",
      "Epoch 183/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4223 - accuracy: 0.8016\n",
      "Epoch 184/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4235 - accuracy: 0.7956\n",
      "Epoch 185/200\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 0.4226 - accuracy: 0.7966\n",
      "Epoch 186/200\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 0.4216 - accuracy: 0.7943\n",
      "Epoch 187/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4224 - accuracy: 0.7966\n",
      "Epoch 188/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4246 - accuracy: 0.7949\n",
      "Epoch 189/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4211 - accuracy: 0.7984\n",
      "Epoch 190/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4220 - accuracy: 0.7988\n",
      "Epoch 191/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4217 - accuracy: 0.8002\n",
      "Epoch 192/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4259 - accuracy: 0.7961\n",
      "Epoch 193/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4225 - accuracy: 0.7954\n",
      "Epoch 194/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4220 - accuracy: 0.7961\n",
      "Epoch 195/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4225 - accuracy: 0.7995\n",
      "Epoch 196/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4234 - accuracy: 0.7947\n",
      "Epoch 197/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4213 - accuracy: 0.8009\n",
      "Epoch 198/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4231 - accuracy: 0.7977\n",
      "Epoch 199/200\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 0.4236 - accuracy: 0.7980\n",
      "Epoch 200/200\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.4258 - accuracy: 0.7933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d0954d9750>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=200, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ea7c7aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type int).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m y_hat]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:103\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    101\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    102\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type int)."
     ]
    }
   ],
   "source": [
    "y_hat = model.predict(X_test)\n",
    "y_hat = [0 if val < 0.5 else 1 for val in y_hat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "364de819",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.asarray(X_test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "922bc22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_hat = model.predict(X_test)\n",
    "y_hat = [0 if val < 0.5 else 1 for val in y_hat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be90458e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7963094393186657"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7bfbbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "{{function_node __wrapped__SaveV2_dtypes_19_device_/job:localhost/replica:0/task:0/device:CPU:0}} Failed to rename: tfmodel\\variables\\variables_temp/part-00000-of-00001.index.tempstate15062483741125533905 to: tfmodel\\variables\\variables_temp/part-00000-of-00001.index : The process cannot access the file because it is being used by another process.\r\n; Broken pipe [Op:SaveV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtfmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: {{function_node __wrapped__SaveV2_dtypes_19_device_/job:localhost/replica:0/task:0/device:CPU:0}} Failed to rename: tfmodel\\variables\\variables_temp/part-00000-of-00001.index.tempstate15062483741125533905 to: tfmodel\\variables\\variables_temp/part-00000-of-00001.index : The process cannot access the file because it is being used by another process.\r\n; Broken pipe [Op:SaveV2]"
     ]
    }
   ],
   "source": [
    "model.save('tfmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9adffdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tfmodel\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tfmodel\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('tfmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7b63e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
